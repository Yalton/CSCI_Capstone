{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadp\n",
    "## GUI frontend for program\n",
    "## Manages realsense cam vision and exporting to .ply file\n",
    "---\n",
    "#### Creation Date 9/7/22\n",
    "#### Author: Dalton Bailey\n",
    "#### Course: CSCI 490\n",
    "#### Instructor Sam Siewert\n",
    "----\n",
    "- **Planning Pothole potential using pointcloud from a ply file, powered by python, pacing on the pipad**\n",
    "- Notebook primarily useful to explain individual code blocks, code functions best when ran using _python3 quadp.py_ or using the script: _./quadp_ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Imports \n",
    "----\n",
    "- yaml: Allows program to save configuration data to yaml file \n",
    "- tkinter: Creates GUI and embedded gui widgets\n",
    "- numpy: Performs complex calculations\n",
    "- cv2: Handles piping camera vision to GUI\n",
    "- atexit: Performs functionality on program exit\n",
    "- os: Allows program to run os commans\n",
    "- themes: Custom library for holding themes\n",
    "- calibration: Calibrates Realsense Camera\n",
    "- calc: Calculation backend (see calc.ipynb)\n",
    "- pyrealsense2: Python Realsense library (allows control of Realsense Camera)\n",
    "- time: Used to time code blocks\n",
    "- PIL: Python Image Library, handles image conversion and processing\n",
    "- webview: Opens embedded webbrowser for Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import atexit\n",
    "import os\n",
    "from os.path import exists\n",
    "from themes import *\n",
    "import calibration as cal\n",
    "from calc import *\n",
    "import pyrealsense2 as rs\n",
    "import time\n",
    "import PIL as pil\n",
    "from PIL import ImageTk\n",
    "from IPython.display import clear_output  # Clear the screen\n",
    "import webview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class variables for gui\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class interface():\n",
    "    # Class variables (Initialize all as none until they are required)\n",
    "    root = None\n",
    "    working_dir = None\n",
    "    output_file = None\n",
    "    scanning = None\n",
    "\n",
    "    # User config variables\n",
    "    conf_file = None\n",
    "    conf = None\n",
    "    username = None\n",
    "    debug = None\n",
    "    units = None\n",
    "    density = None\n",
    "    densityUnit = None\n",
    "\n",
    "    # Global GUI Variables\n",
    "    theme = None\n",
    "    screen_width = None\n",
    "    screen_height = None\n",
    "\n",
    "    # Global Tkinter Widgets\n",
    "    video_out = None\n",
    "    cam_controls = None\n",
    "    s_scan_button = None\n",
    "    export_button = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GUI Constructor \n",
    "----\n",
    "- Determines width of screen \n",
    "- Sets global Tkinter widgets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Constructor for Interface object\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()  # Calls tktinker object and sets self.root to be equal to it\n",
    "        self.calcBackend = pholeCalc()  # Initialize the calculation backend\n",
    "        self.working_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "        #self.working_dir = os.getcwd()\n",
    "        self.conf_file = self.working_dir+'/data/conf.yml'\n",
    "\n",
    "        # Generate unique hash to store export of scan (takes some time)\n",
    "        self.output_file = self.working_dir + \"/data/ply/\" + self.calcBackend.hash(\n",
    "            (''.join(random.choice(string.ascii_letters) for i in range(7)))) + \".ply\"\n",
    "\n",
    "        # Load configuration from yaml file\n",
    "        self.loadConfig()\n",
    "\n",
    "        self.screen_width = self.root.winfo_screenwidth()  # Get width of current screen\n",
    "        self.screen_height = self.root.winfo_screenheight()  # Get height of current screen\n",
    "\n",
    "        # Set program title and geometry of root gui\n",
    "        self.root.title(\"Quad-P\")\n",
    "        self.root.geometry(\"%dx%d\" % (self.screen_width, self.screen_height))\n",
    "\n",
    "        # Configure GUI title and Geometry\n",
    "        self.root.configure(background=themes[self.theme]['background_colo'])\n",
    "\n",
    "        # Create Location for video feed in GUI\n",
    "        self.video_out = tk.Canvas(\n",
    "            self.root, bg=\"#000000\", height=480, width=640, borderwidth=5, relief=\"sunken\")\n",
    "        self.video_out.grid(column=0, row=1, columnspan=10,\n",
    "                            pady=35, ipadx=5, ipady=5, sticky=tk.NS)\n",
    "        # Create Location for text output in GUI\n",
    "        self.cam_controls = tk.Label(self.root, fg=themes[self.theme]['background_colo'], bg=themes[self.theme]['background_colo'], height=round(\n",
    "            self.screen_height*0.002555), width=round(self.screen_width*0.059))\n",
    "        self.cam_controls.grid(column=0, row=2, columnspan=10,\n",
    "                               sticky=tk.NS)\n",
    "\n",
    "        self.s_scan_button = tk.Button(\n",
    "            self.cam_controls, text=\"Enable Camera\", command=lambda: self.startScan())\n",
    "        self.s_scan_button.grid(column=1, row=0, padx=20)\n",
    "\n",
    "        self.export_button = tk.Button(\n",
    "            self.cam_controls, text=\"Export Scan\", command=lambda: self.exportScan())\n",
    "        self.export_button.grid(column=3, row=0, padx=20)\n",
    "\n",
    "        # Create Location for text output in GUI\n",
    "        self.b_data = tk.Label(self.root, fg=themes[self.theme]['main_colo'], bg=themes[self.theme]['main_colo'], height=round(\n",
    "            self.screen_height*0.00555), width=round(self.screen_width*0.059), borderwidth=5, relief=\"solid\")\n",
    "        self.b_data.grid(column=0, row=3, columnspan=10,\n",
    "                         sticky=tk.SW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Livestream Camera's Vision\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def startScan(self):\n",
    "        pipe = rs.pipeline()                      # Create a pipeline\n",
    "        cfg = rs.config()                         # Create a default configuration\n",
    "        print(\"[QUAD_P] Pipeline is created\") if gui.debug else None\n",
    "\n",
    "        print(\"[QUAD_P] Searching For Realsense Devices..\") if gui.debug else None\n",
    "        selected_devices = []                     # Store connected device(s)\n",
    "\n",
    "        for d in rs.context().devices:\n",
    "            selected_devices.append(d)\n",
    "            print(d.get_info(rs.camera_info.name))\n",
    "        if not selected_devices:\n",
    "            print(\"No RealSense device is connected!\")\n",
    "            return\n",
    "\n",
    "        print(\n",
    "            \"[QUAD_P] (debug) Streaming camera vision to GUI... \") if gui.debug else None\n",
    "\n",
    "        rgb_sensor = depth_sensor = None\n",
    "\n",
    "        for device in selected_devices:\n",
    "            print(\"Required sensors for device:\",\n",
    "                  device.get_info(rs.camera_info.name))\n",
    "            for s in device.sensors:                              # Show available sensors in each device\n",
    "                if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "                    print(\"[QUAD_P] - RGB sensor found\") if gui.debug else None\n",
    "                    rgb_sensor = s                                # Set RGB sensor\n",
    "                if s.get_info(rs.camera_info.name) == 'Stereo Module':\n",
    "                    depth_sensor = s                              # Set Depth sensor\n",
    "                    print(\"[QUAD_P] - Depth sensor found\") if gui.debug else None\n",
    "        # Mapping depth data into RGB color space\n",
    "        colorizer = rs.colorizer()\n",
    "        # Configure and start the pipeline\n",
    "        profile = pipe.start(cfg)\n",
    "\n",
    "        # Show 1 row with 2 columns for Depth and RGB frames\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(24, 8))\n",
    "        # Title for each frame\n",
    "        title = [\"Depth Image\", \"RGB Image\"]\n",
    "\n",
    "        # Skip first frames to give syncer and auto-exposure time to adjust\n",
    "        for _ in range(10):\n",
    "            frameset = pipe.wait_for_frames()\n",
    "\n",
    "        # Increase to display more frames\n",
    "        for _ in range(30):\n",
    "            # Read frames from the file, packaged as a frameset\n",
    "            frameset = pipe.wait_for_frames()\n",
    "            depth_frame = frameset.get_depth_frame()              # Get depth frame\n",
    "            color_frame = frameset.get_color_frame()              # Get RGB frame\n",
    "\n",
    "            # This is what we'll actually display\n",
    "            colorized_streams = []\n",
    "            if depth_frame:\n",
    "                colorized_streams.append(np.asanyarray(\n",
    "                    colorizer.colorize(depth_frame).get_data()))\n",
    "            if color_frame:\n",
    "                colorized_streams.append(np.asanyarray(color_frame.get_data()))\n",
    "\n",
    "            # Iterate over all (Depth and RGB) colorized frames\n",
    "            for i, ax in enumerate(axs.flatten()):\n",
    "                if i >= len(colorized_streams):\n",
    "                    continue          # When getting less frames than expected\n",
    "                # Set the current Axes and Figure\n",
    "                plt.sca(ax)\n",
    "                # colorized frame to display\n",
    "                plt.imshow(colorized_streams[i])\n",
    "                # Add title for each subplot\n",
    "                plt.title(title[i])\n",
    "            # Clear any previous frames from the display\n",
    "            clear_output(wait=True)\n",
    "            # Adjusts display size to fit frames\n",
    "            plt.tight_layout()\n",
    "            # Make the playback slower so it's noticeable\n",
    "            plt.pause(1)\n",
    "\n",
    "        pipe.stop()                                               # Stop the pipeline\n",
    "        print(\"[QUAD_P] Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Livestreaming Camera Vision \n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def stopScan(self):\n",
    "        print(\"[QUAD_P] (debug) Disabling live feed...\") if gui.debug else None\n",
    "        self.scanning = False\n",
    "        self.s_scan_button = tk.Button(\n",
    "            self.cam_controls, text=\"Enable Camera\", command=lambda: self.stopScan())\n",
    "        self.s_scan_button.grid(column=1, row=0, padx=20)\n",
    "        if self.export_scan:\n",
    "            self.exportScan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Scan into a .ply file\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def exportScan(self):\n",
    "        start_time = time.process_time()  # start timer\n",
    "        print(\"Searching For Realsense Devices..\")\n",
    "        selected_devices = []                     # Store connected device(s)\n",
    "\n",
    "        for d in rs.context().devices:\n",
    "            selected_devices.append(d)\n",
    "            print(d.get_info(rs.camera_info.name))\n",
    "        if not selected_devices:\n",
    "            print(\"No RealSense device is connected!\")\n",
    "            return\n",
    "\n",
    "        print(\n",
    "            \"[QUAD_P] (debug) Exporting camera's vison as .ply file...\") if gui.debug else None\n",
    "        # Declare pointcloud object, for calculating pointclouds and texture mappings\n",
    "        pc = rs.pointcloud()\n",
    "        # We want the points object to be persistent so we can display the last cloud when a frame drops\n",
    "        points = rs.points()\n",
    "\n",
    "        # Declare RealSense pipeline, encapsulating the actual device and sensors\n",
    "        pipe = rs.pipeline()\n",
    "        config = rs.config()\n",
    "        # Enable depth stream\n",
    "        config.enable_stream(rs.stream.depth)\n",
    "\n",
    "        # Start streaming with chosen configuration\n",
    "        pipe.start(config)\n",
    "\n",
    "        # We'll use the colorizer to generate texture for our PLY\n",
    "        # (alternatively, texture can be obtained from color or infrared stream)\n",
    "        colorizer = rs.colorizer()\n",
    "\n",
    "        try:\n",
    "            # Give camera time to adjust to exposure\n",
    "            for x in range(10):\n",
    "                pipe.wait_for_frames()\n",
    "\n",
    "            # Wait for the next set of frames from the camera\n",
    "            frames = pipe.wait_for_frames()\n",
    "            colorized = colorizer.process(frames)\n",
    "\n",
    "            # Create save_to_ply object\n",
    "            ply = rs.save_to_ply(self.output_file)\n",
    "\n",
    "            # Set options to the desired values\n",
    "            # In this example we'll generate a textual PLY with normals (mesh is already created by default)\n",
    "            ply.set_option(rs.save_to_ply.option_ply_binary, False)\n",
    "            ply.set_option(rs.save_to_ply.option_ply_normals, True)\n",
    "\n",
    "            print(\"[QUAD_P] (debug) Saving to \",\n",
    "                  self.output_file, \"...\") if gui.debug else None\n",
    "\n",
    "            # Apply the processing block to the frameset which contains the depth frame and the texture\n",
    "            ply.process(colorized)\n",
    "\n",
    "            print(f\"[QUAD_P] (debug) Export Complete!\\n Elapsed time was \",\n",
    "                  (time.process_time() - start_time) * 1000, \"ms.\\n\") if gui.debug else None\n",
    "        finally:\n",
    "            pipe.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
